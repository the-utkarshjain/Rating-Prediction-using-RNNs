Hidden Size = 256
Architecture: UniLSTM -> Linear (hidden, hidden/2) -> Relu -> Linear (hidden/2,1)

Epoch : 1/10, i: 244/2446, Training Loss: 2.716082811355591
Epoch : 1/10, i: 488/2446, Training Loss: 2.1637966632843018
Epoch : 1/10, i: 732/2446, Training Loss: 1.8196302652359009
Epoch : 1/10, i: 976/2446, Training Loss: 1.5363885164260864
Epoch : 1/10, i: 1220/2446, Training Loss: 1.4780019521713257
Epoch : 1/10, i: 1464/2446, Training Loss: 1.4343944787979126
Epoch : 1/10, i: 1708/2446, Training Loss: 1.4308820962905884
Epoch : 1/10, i: 1952/2446, Training Loss: 1.3635458946228027
Epoch : 1/10, i: 2196/2446, Training Loss: 1.330588936805725
Epoch : 1/10, i: 2440/2446, Training Loss: 1.2991019487380981
==============================
Epoch 1 Summary
Training Loss: 1.6567981243133545
Validation Loss: 1.3335211277008057
==============================
Epoch : 2/10, i: 244/2446, Training Loss: 1.2684369087219238
Epoch : 2/10, i: 488/2446, Training Loss: 1.2716610431671143
Epoch : 2/10, i: 732/2446, Training Loss: 1.2693612575531006
Epoch : 2/10, i: 976/2446, Training Loss: 1.2187355756759644
Epoch : 2/10, i: 1220/2446, Training Loss: 1.217345118522644
Epoch : 2/10, i: 1464/2446, Training Loss: 1.2336177825927734
Epoch : 2/10, i: 1708/2446, Training Loss: 1.2409919500350952
Epoch : 2/10, i: 1952/2446, Training Loss: 1.2162388563156128
Epoch : 2/10, i: 2196/2446, Training Loss: 1.1923518180847168
Epoch : 2/10, i: 2440/2446, Training Loss: 1.1724306344985962
==============================
Epoch 2 Summary
Training Loss: 1.2304145097732544
Validation Loss: 1.1781638860702515
==============================
Epoch : 3/10, i: 244/2446, Training Loss: 1.1520315408706665
Epoch : 3/10, i: 488/2446, Training Loss: 1.1511667966842651
Epoch : 3/10, i: 732/2446, Training Loss: 1.1680418252944946
Epoch : 3/10, i: 976/2446, Training Loss: 1.1171362400054932
Epoch : 3/10, i: 1220/2446, Training Loss: 1.1208791732788086
Epoch : 3/10, i: 1464/2446, Training Loss: 1.1486289501190186
Epoch : 3/10, i: 1708/2446, Training Loss: 1.1495461463928223
Epoch : 3/10, i: 1952/2446, Training Loss: 1.1353602409362793
Epoch : 3/10, i: 2196/2446, Training Loss: 1.110318899154663
Epoch : 3/10, i: 2440/2446, Training Loss: 1.1008281707763672
==============================
Epoch 3 Summary
Training Loss: 1.1357699632644653
Validation Loss: 1.1350300312042236
==============================
Epoch : 4/10, i: 244/2446, Training Loss: 1.085801124572754
Epoch : 4/10, i: 488/2446, Training Loss: 1.0770341157913208
Epoch : 4/10, i: 732/2446, Training Loss: 1.1006108522415161
Epoch : 4/10, i: 976/2446, Training Loss: 1.044970989227295
Epoch : 4/10, i: 1220/2446, Training Loss: 1.0523430109024048
Epoch : 4/10, i: 1464/2446, Training Loss: 1.0818521976470947
Epoch : 4/10, i: 1708/2446, Training Loss: 1.0846117734909058
Epoch : 4/10, i: 1952/2446, Training Loss: 1.0711241960525513
Epoch : 4/10, i: 2196/2446, Training Loss: 1.0457918643951416
Epoch : 4/10, i: 2440/2446, Training Loss: 1.0397984981536865
==============================
Epoch 4 Summary
Training Loss: 1.0688244104385376
Validation Loss: 1.1093194484710693
==============================
Epoch : 5/10, i: 244/2446, Training Loss: 1.0269982814788818
Epoch : 5/10, i: 488/2446, Training Loss: 1.017491102218628
Epoch : 5/10, i: 732/2446, Training Loss: 1.040079951286316
Epoch : 5/10, i: 976/2446, Training Loss: 0.9833576083183289
Epoch : 5/10, i: 1220/2446, Training Loss: 0.993577778339386
Epoch : 5/10, i: 1464/2446, Training Loss: 1.0194646120071411
Epoch : 5/10, i: 1708/2446, Training Loss: 1.0200470685958862
Epoch : 5/10, i: 1952/2446, Training Loss: 1.003670573234558
Epoch : 5/10, i: 2196/2446, Training Loss: 0.9792943596839905
Epoch : 5/10, i: 2440/2446, Training Loss: 0.9724182486534119
==============================
Epoch 5 Summary
Training Loss: 1.0061088800430298
Validation Loss: 1.0972601175308228
==============================
Epoch : 6/10, i: 244/2446, Training Loss: 0.9674035906791687
Epoch : 6/10, i: 488/2446, Training Loss: 0.9615095853805542
Epoch : 6/10, i: 732/2446, Training Loss: 0.9822041988372803
Epoch : 6/10, i: 976/2446, Training Loss: 0.9241998791694641
Epoch : 6/10, i: 1220/2446, Training Loss: 0.9275563359260559
Epoch : 6/10, i: 1464/2446, Training Loss: 0.9555128812789917
Epoch : 6/10, i: 1708/2446, Training Loss: 0.9598977565765381
Epoch : 6/10, i: 1952/2446, Training Loss: 0.9321611523628235
Epoch : 6/10, i: 2196/2446, Training Loss: 0.9128034114837646
Epoch : 6/10, i: 2440/2446, Training Loss: 0.9023429155349731
==============================
Epoch 6 Summary
Training Loss: 0.9430615305900574
Validation Loss: 1.1025354862213135
==============================
Epoch : 7/10, i: 244/2446, Training Loss: 0.909393310546875
Epoch : 7/10, i: 488/2446, Training Loss: 0.9056310653686523
Epoch : 7/10, i: 732/2446, Training Loss: 0.9214137196540833
Epoch : 7/10, i: 976/2446, Training Loss: 0.8640889525413513
Epoch : 7/10, i: 1220/2446, Training Loss: 0.868148148059845
Epoch : 7/10, i: 1464/2446, Training Loss: 0.8885272145271301
Epoch : 7/10, i: 1708/2446, Training Loss: 0.9093252420425415
Epoch : 7/10, i: 1952/2446, Training Loss: 0.8660230040550232
Epoch : 7/10, i: 2196/2446, Training Loss: 0.84450763463974
Epoch : 7/10, i: 2440/2446, Training Loss: 0.8352034091949463
==============================
Epoch 7 Summary
Training Loss: 0.8816782832145691
Validation Loss: 1.1169551610946655
==============================
Epoch : 8/10, i: 244/2446, Training Loss: 0.8470069766044617
Epoch : 8/10, i: 488/2446, Training Loss: 0.8392363786697388
Epoch : 8/10, i: 732/2446, Training Loss: 0.866188645362854
Epoch : 8/10, i: 976/2446, Training Loss: 0.8058887124061584
Epoch : 8/10, i: 1220/2446, Training Loss: 0.8032755851745605
Epoch : 8/10, i: 1464/2446, Training Loss: 0.8216201663017273
Epoch : 8/10, i: 1708/2446, Training Loss: 0.8537445664405823
Epoch : 8/10, i: 1952/2446, Training Loss: 0.803299605846405
Epoch : 8/10, i: 2196/2446, Training Loss: 0.7797629237174988
Epoch : 8/10, i: 2440/2446, Training Loss: 0.7708030939102173
==============================
Epoch 8 Summary
Training Loss: 0.8194368481636047
Validation Loss: 1.1550723314285278
==============================
Epoch : 9/10, i: 244/2446, Training Loss: 0.7943276762962341
Epoch : 9/10, i: 488/2446, Training Loss: 0.7821477651596069
Epoch : 9/10, i: 732/2446, Training Loss: 0.7993773221969604
Epoch : 9/10, i: 976/2446, Training Loss: 0.7463254332542419
Epoch : 9/10, i: 1220/2446, Training Loss: 0.742470383644104
Epoch : 9/10, i: 1464/2446, Training Loss: 0.7541617155075073
Epoch : 9/10, i: 1708/2446, Training Loss: 0.7912640571594238
Epoch : 9/10, i: 1952/2446, Training Loss: 0.7348343133926392
Epoch : 9/10, i: 2196/2446, Training Loss: 0.7159139513969421
Epoch : 9/10, i: 2440/2446, Training Loss: 0.7076992392539978
==============================
Epoch 9 Summary
Training Loss: 0.7571732997894287
Validation Loss: 1.1665297746658325
==============================
Epoch : 10/10, i: 244/2446, Training Loss: 0.7332015037536621
Epoch : 10/10, i: 488/2446, Training Loss: 0.7372211217880249
Epoch : 10/10, i: 732/2446, Training Loss: 0.7386679649353027
Epoch : 10/10, i: 976/2446, Training Loss: 0.7001332640647888
Epoch : 10/10, i: 1220/2446, Training Loss: 0.6942614912986755
Epoch : 10/10, i: 1464/2446, Training Loss: 0.7035952210426331
Epoch : 10/10, i: 1708/2446, Training Loss: 0.7426479458808899
Epoch : 10/10, i: 1952/2446, Training Loss: 0.6777404546737671
Epoch : 10/10, i: 2196/2446, Training Loss: 0.6658839583396912
Epoch : 10/10, i: 2440/2446, Training Loss: 0.6699925661087036
==============================
Epoch 10 Summary
Training Loss: 0.7066090106964111
Validation Loss: 1.2085257768630981
==============================